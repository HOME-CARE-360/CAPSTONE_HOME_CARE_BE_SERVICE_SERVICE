import os
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import psycopg2
import joblib

os.makedirs('model', exist_ok=True)

# Load env and connect
dsn = os.getenv("DATABASE_URL_MAIN")
if not dsn:
    raise RuntimeError("DATABASE_URL_MAIN ch∆∞a ƒë∆∞·ª£c thi·∫øt l·∫≠p")
conn = psycopg2.connect(dsn)
cur = conn.cursor()

# Truy v·∫•n ch√≠nh x√°c theo schema Prisma
cur.execute("""
    SELECT 
        cp.id,
        COALESCE(rp.points, 0) AS rewardPoints,
        (SELECT COUNT(*) FROM "Booking" b WHERE b."customerId" = cp.id) AS totalBookings,
        EXISTS(SELECT 1 FROM "RecurringBooking" r WHERE r."customerId" = cp.id) AS hasRecurring,
        (SELECT json_agg(message) 
         FROM "ChatMessage" 
         WHERE "customerId" = cp.id AND sender = 'user') AS chatKeywords,
        (SELECT "packageId"
         FROM "PackageRecommendation"
         WHERE "customerId" = cp.id
         ORDER BY "recommendedAt" DESC
         LIMIT 1) AS packageId
    FROM "CustomerProfile" cp
    LEFT JOIN "RewardPoint" rp ON rp."customerId" = cp.id;
""")

# T·∫°o d·ªØ li·ªáu hu·∫•n luy·ªán
rows = []
for cid, pts, cnt, rec, msgs, pkg_id in cur.fetchall():
    if pkg_id is None:
        continue  # b·ªè kh√°ch ch∆∞a c√≥ package recommendation
    keywords = []
    if msgs:
        keywords = [str(m).lower() for m in msgs if isinstance(m, str)]
    rows.append({
        'rewardPoints': pts,
        'totalBookings': cnt,
        'hasRecurring': int(rec),
        'chatKeywords': keywords,
        'label': pkg_id
    })

cur.close()
conn.close()

df = pd.DataFrame(rows)

# N·∫øu kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ train th√¨ b·ªè qua, kh√¥ng raise
if df.empty:
    print("‚ö†Ô∏è Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªß ƒëi·ªÅu ki·ªán ƒë·ªÉ hu·∫•n luy·ªán model. B·ªè qua...")
    exit(0)

vc = df['label'].value_counts()
remove = vc[vc < 2].index.tolist()
if remove:
    print("‚ö†Ô∏è B·ªè c√°c label √≠t m·∫´u:", remove)
df = df[df['label'].isin(vc[vc >= 2].index)]

# N·∫øu sau khi l·ªçc m√† v·∫´n tr·ªëng th√¨ c≈©ng d·ª´ng nh·∫π nh√†ng
if df.empty:
    print("‚ö†Ô∏è Kh√¥ng c√≤n d·ªØ li·ªáu sau khi l·ªçc c√°c label √≠t xu·∫•t hi·ªán. B·ªè qua...")
    exit(0)

# Chu·∫©n h√≥a d·ªØ li·ªáu
mlb = MultiLabelBinarizer()
Xk = mlb.fit_transform(df['chatKeywords'])
X = pd.concat([
    df[['rewardPoints', 'totalBookings', 'hasRecurring']].reset_index(drop=True),
    pd.DataFrame(Xk, columns=mlb.classes_)
], axis=1)
y = df['label']

# Chia t·∫≠p train/test
n_samples = len(y)
n_classes = y.nunique()
default_frac = 0.2
min_frac = n_classes / n_samples
test_frac = max(default_frac, min_frac)

print(f"Total samples: {n_samples}, classes: {n_classes}")
print(f"Using test_size = {test_frac:.3f} ({int(test_frac*n_samples)} samples)")

try:
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_frac, random_state=42, stratify=y
    )
except ValueError as e:
    print("‚ö†Ô∏è Stratified split failed:", e)
    print("‚Üí Fallback sang random split (no stratify)")
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_frac, random_state=42, stratify=None
    )

# Train m√¥ h√¨nh
clf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
clf.fit(X_train, y_train)

# ƒê√°nh gi√°
y_pred = clf.predict(X_test)
print("‚úÖ Accuracy:", accuracy_score(y_test, y_pred))
print("üìä Classification Report:\n", classification_report(y_test, y_pred, zero_division=0))

# Confusion matrix
cm = confusion_matrix(y_test, y_pred, labels=clf.classes_)
plt.figure(figsize=(10, 6))
sns.heatmap(cm, annot=True, fmt='d', xticklabels=clf.classes_, yticklabels=clf.classes_)
plt.xlabel("Predicted")
plt.ylabel("True")
plt.title("Confusion Matrix")
plt.tight_layout()
plt.savefig("model/confusion_matrix.png")

# Save model
joblib.dump(clf, 'model/recommendation_model.pkl')
joblib.dump(mlb, 'model/keyword_vectorizer.pkl')
print("‚úÖ Models saved under ./model/")
